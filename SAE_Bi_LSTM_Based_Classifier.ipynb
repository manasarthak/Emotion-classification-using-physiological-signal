{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1iSADVSlLJ4zDC_Ex5Ym8uFK1-f47qPNf",
      "authorship_tag": "ABX9TyMAXrUjPDrDPOr7e0D1saze",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manasarthak/Emotion-classification-using-physiological-signal/blob/main/SAE_Bi_LSTM_Based_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.utils import io\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import scipy.io\n",
        "from scipy import signal,integrate\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input,Dense,LSTM,Dropout\n",
        "\n",
        "import mne\n",
        "import math\n",
        "\n",
        "import pickle\n",
        "\n",
        "\n",
        "n_seg=125\n",
        "n_points=8064\n",
        "bottleneck=128"
      ],
      "metadata": {
        "id": "V-_RJyF-o2Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your data\n",
        "pyt = np.load('DEAP/s01.dat', allow_pickle=True, encoding='latin1')\n",
        "data = pyt['data'][:, 0:32, 3 * 128:]\n",
        "labels = pyt['labels'][:, :3]\n",
        "print(data.shape)\n",
        "print(labels.shape)\n",
        "print(np.amax(data))\n",
        "print(np.amin(data))"
      ],
      "metadata": {
        "id": "5uNj-VqYW0e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize(a,multiple):\n",
        "    std=np.std(a)\n",
        "    mean=np.mean(a)\n",
        "    a=(a-mean)/std\n",
        "    return multiple*a"
      ],
      "metadata": {
        "id": "9jsY6duNpGUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convertAllData():\n",
        "    valence_labels_all, valence_data_all = [], []\n",
        "    arousal_labels_all, arousal_data_all = [], []\n",
        "    dominance_labels_all, dominance_data_all = [], []\n",
        "\n",
        "    for i in range(32):\n",
        "        file_number = str(i+1).zfill(2)  # Add leading zero if needed\n",
        "        file_name = 'DEAP/s' + file_number + '.dat'\n",
        "        print(file_name)\n",
        "\n",
        "        valence_labels, valence_data, arousal_labels, arousal_data, dominance_labels, dominance_data = convertOneSubjectData(file_name)\n",
        "\n",
        "        valence_labels_all.extend(valence_labels)\n",
        "        valence_data_all.extend([standardize(d, 1) for d in valence_data])\n",
        "\n",
        "        arousal_labels_all.extend(arousal_labels)\n",
        "        arousal_data_all.extend([standardize(d, 1) for d in arousal_data])\n",
        "\n",
        "        dominance_labels_all.extend(dominance_labels)\n",
        "        dominance_data_all.extend([standardize(d, 1) for d in dominance_data])\n",
        "\n",
        "    valence_labels_all = np.array(valence_labels_all)\n",
        "    valence_data_all = np.array(valence_data_all)\n",
        "    arousal_labels_all = np.array(arousal_labels_all)\n",
        "    arousal_data_all = np.array(arousal_data_all)\n",
        "    dominance_labels_all = np.array(dominance_labels_all)\n",
        "    dominance_data_all = np.array(dominance_data_all)\n",
        "\n",
        "    print(\"Valence trial data for all subjects:\", valence_labels_all.shape, valence_data_all.shape)\n",
        "    print(\"Arousal trial data for all subjects:\", arousal_labels_all.shape, arousal_data_all.shape)\n",
        "    print(\"Dominance trial data for all subjects:\", dominance_labels_all.shape, dominance_data_all.shape)\n",
        "\n",
        "    # Save numpy arrays of total data to files\n",
        "    np.save('DEAP/valence/all_valence_labels.npy', valence_labels_all)\n",
        "    np.save('DEAP/valence/all_valence_data.npy', valence_data_all)\n",
        "    np.save('DEAP/arousal/all_arousal_labels.npy', arousal_labels_all)\n",
        "    np.save('DEAP/arousal/all_arousal_data.npy', arousal_data_all)\n",
        "    np.save('DEAP/dominance/all_dominance_labels.npy', dominance_labels_all)\n",
        "    np.save('DEAP/dominance/all_dominance_data.npy', dominance_data_all)"
      ],
      "metadata": {
        "id": "owPQHwehTV52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convertAllData()"
      ],
      "metadata": {
        "id": "MSqti8N7W9o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(dim):\n",
        "    if dim=='valence':\n",
        "        labels_all=np.load('DEAP/valence/' + 'all_valence_labels.npy',allow_pickle=True)\n",
        "        data_all=np.load('DEAP/valence/' + 'all_valence_data.npy',allow_pickle=True)\n",
        "        print(\"Valence :\",labels_all.shape,data_all.shape)\n",
        "    elif dim=='arousal':\n",
        "        labels_all=np.load('DEAP/arousal/'+'all_arousal_labels.npy',allow_pickle=True)\n",
        "        data_all=np.load('DEAP/arousal/'+'all_arousal_data.npy',allow_pickle=True)\n",
        "        print(\"Arousal: \",labels_all.shape,data_all.shape)\n",
        "    elif dim=='dominance':\n",
        "        labels_all=np.load('DEAP/dominance/all_dominance_labels.npy',allow_pickle=True)\n",
        "        data_all=np.load('DEAP/dominance/all_dominance_data.npy',allow_pickle=True)\n",
        "        print(\"Dominance: \",labels_all.shape,data_all.shape)\n",
        "    return labels_all,data_all"
      ],
      "metadata": {
        "id": "6lPz4c9XqT82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature extraction using PSD\n",
        "def PSD_extraction(data):\n",
        "    info = mne.create_info(ch_names=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'], sfreq=128)\n",
        "    raw = mne.io.RawArray(data, info, first_samp=0, copy='auto', verbose=None)\n",
        "    # Changes for hanning window\n",
        "    n_overlap = n_points // 2  # 50% overlap\n",
        "    n_per_seg = n_points  # Window size is the same as the data segment size\n",
        "\n",
        "    psd_origin, f = mne.time_frequency.psd_welch(raw, fmin=0, fmax=60, n_fft=n_points, n_overlap=n_overlap,\n",
        "                                                 n_per_seg=n_per_seg, picks='all', window='hann', average=None)\n",
        "    psd = np.moveaxis(psd_origin, -1, 0)\n",
        "    band_power = []\n",
        "    for segment in psd:\n",
        "        segment_band_p = []  # band power for all channels in one segment\n",
        "        for psd_channel in segment:\n",
        "            y_int = integrate.cumtrapz(psd_channel, f, initial=0)  # integrate this to calculate bandpower\n",
        "            one_band_p = np.array([y_int[7] - y_int[4], y_int[13] - y_int[8], y_int[30] - y_int[14], y_int[51] - y_int[31]])\n",
        "            segment_band_p.append(one_band_p)\n",
        "        band_power.append(segment_band_p)\n",
        "\n",
        "    band_power = np.array(band_power)\n",
        "    band_power = np.moveaxis(band_power, -1, 1)\n",
        "    band_power = band_power.reshape((n_seg, bottleneck * 4))\n",
        "    band_power = 10 * band_power\n",
        "    return band_power"
      ],
      "metadata": {
        "id": "xFe4W4XCXC8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#code for transforming eeg data shape\n",
        "# change dimension from (849, 32, 7680)to (849, 8064, 32) then to (6846336, 32) for input 32-dimension vector to autoencoder\n",
        "def vector_transform(data):\n",
        "    vectors = np.moveaxis(data, 1, -1)\n",
        "    vectors = vectors.reshape((vectors.shape[0]*vectors.shape[1], vectors.shape[2]))\n",
        "    return vectors\n",
        "\n",
        "# change output of autoencoder dimension from (6846336, 12) to (849, 8064, 12) then to (849, 12, 8064)\n",
        "def inverse_vector_transform(vectors):\n",
        "    data = vectors.reshape((int(vectors.shape[0]/n_points), n_points, vectors.shape[1]))\n",
        "    data = np.moveaxis(data, -1, 1)\n",
        "    return data"
      ],
      "metadata": {
        "id": "CvBX6LyYUGfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10 fold cross verification(dividing the data so that it beconmes a multiple of 10)\n",
        "data_all, labels_all = shuffle(data_all_ar, labels_all_ar, random_state=42)\n",
        "n = len(labels_all)\n",
        "fold_n = math.floor(n / 10)\n",
        "data_all, labels_all = data_all[:10 * fold_n], labels_all[:10 * fold_n]"
      ],
      "metadata": {
        "id": "ZeJez7-Ho2Kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process(test_fold_number):\n",
        "    train_data = np.concatenate((data_all[:test_fold_number * fold_n], data_all[fold_n + test_fold_number * fold_n:]), axis=0)\n",
        "    train_labels = np.concatenate((labels_all[:test_fold_number * fold_n], labels_all[fold_n + test_fold_number * fold_n:]), axis=0)\n",
        "    test_data = data_all[test_fold_number * fold_n:fold_n + test_fold_number * fold_n]\n",
        "    test_labels = labels_all[test_fold_number * fold_n:fold_n + test_fold_number * fold_n]\n",
        "\n",
        "    train_vectors = vector_transform(train_data)\n",
        "    test_vectors = vector_transform(test_data)\n",
        "\n",
        "    input_ = Input(shape=(32,))\n",
        "    encoded = Dense(128, activation=None)(input_)\n",
        "    bottleneck_layer = Dense(bottleneck, activation=None)(encoded)\n",
        "    decoded = Dense(128, activation=None)(bottleneck_layer)\n",
        "    decoded = Dense(32, activation=None)(decoded)\n",
        "    autoencoder = Model(input_, decoded)\n",
        "\n",
        "    encoder = Model(input_, bottleneck_layer)\n",
        "\n",
        "    decoder_input_layer = Input(shape=(bottleneck,))\n",
        "    decoder_layer = autoencoder.layers[-2](decoder_input_layer)\n",
        "    decoder_layer = autoencoder.layers[-1](decoder_layer)\n",
        "    decoder = Model(decoder_input_layer, decoder_layer)\n",
        "\n",
        "    autoencoder.compile(optimizer='SGD', loss='mse', metrics=['accuracy'])\n",
        "    autoencoder.fit(train_vectors, train_vectors, epochs=1, batch_size=64, shuffle=True, validation_data=(test_vectors, test_vectors))\n",
        "    autoencoder.save(\"../Results/autoencoder_model/autoencoder_model_test_fold_\" + str(test_fold_number))\n",
        "\n",
        "    train_data_encoded = encoder.predict(train_vectors)\n",
        "    train_data_encoded = inverse_vector_transform(train_data_encoded)\n",
        "    test_data_encoded = encoder.predict(test_vectors)\n",
        "    test_data_encoded = inverse_vector_transform(test_data_encoded)\n",
        "\n",
        "    train_band_power = []\n",
        "    for data in train_data_encoded:\n",
        "        with io.capture_output() as captured:\n",
        "            trial_band_power = PSD_extraction(data)\n",
        "        train_band_power.append(trial_band_power)\n",
        "    train_band_power = np.array(train_band_power)\n",
        "\n",
        "    test_band_power = []\n",
        "    for data in test_data_encoded:\n",
        "        with io.capture_output() as captured:\n",
        "            trial_band_power = PSD_extraction(data)\n",
        "        test_band_power.append(trial_band_power)\n",
        "    test_band_power = np.array(test_band_power)\n",
        "\n",
        "    x = Input(shape=(n_seg, bottleneck * 4))\n",
        "    x1 = Bidirectional(LSTM(n_seg))(x)\n",
        "    x2 = Dense(n_seg)(x1)\n",
        "    output = Dense(1, activation=\"sigmoid\")(x2)\n",
        "    model = Model(x, output)\n",
        "\n",
        "    model.compile(optimizer='SGD', loss='mse', metrics=['accuracy'])\n",
        "    history = model.fit(train_band_power, train_labels, epochs=30, validation_data=(test_band_power, test_labels))\n",
        "    print(\"Highest accuracy: \" + str(max(history.history['val_accuracy'])))\n",
        "    model.save(\"../Results/LSTM_model/LSTM_model_test_fold_\" + str(test_fold_number))"
      ],
      "metadata": {
        "id": "2Xwne21L3501"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    print(\"********** Test Fold \" + str(i) + \" ************\")\n",
        "    process(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqSsfzUWo2Ig",
        "outputId": "0295be08-4d67-41b9-8087-96ea82588cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Barycenters are loaded\n"
          ]
        }
      ]
    }
  ]
}